import firebase_admin
from firebase_admin import credentials, firestore
from base_conhecimento import SOLUCOES_CONHECIDAS
import os
from dotenv import load_dotenv
import time

# For√ßando o modo REST para evitar lat√™ncia de 60s
os.environ["transport"] = "rest" 

from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

load_dotenv()

# Inicializa√ß√£o segura do Firebase
if not firebase_admin._apps:
    cred = credentials.Certificate("agente-helpdesk-piloto-firebase-adminsdk-fbsvc-85954069f2.json")
    firebase_admin.initialize_app(cred)
db = firestore.client()

class MotorIA:
    def __init__(self):
        # 1. Recria√ß√£o da base de conhecimento para o FAISS
        self.documentos = [
            Document(
                page_content=f"Sistema: {item['sistema']}. Problema: {' '.join(item['palavras_chave'])}. Resposta: {item['resposta']}",
                metadata={"sistema": item['sistema'], "resposta": item['resposta']}
            ) for item in SOLUCOES_CONHECIDAS
        ]
        self.embeddings = GoogleGenerativeAIEmbeddings(model="models/gemini-embedding-001")
        self.vectorstore = FAISS.from_documents(self.documentos, self.embeddings)
        
        # 2. Configura√ß√£o do Modelo (Gemini Flash est√°vel da sua lista)
        self.llm = ChatGoogleGenerativeAI(
            model="models/gemini-flash-latest", 
            temperature=0.1,
            max_output_tokens=800,
            max_retries=0, 
            transport="rest" 
        )

    def processar_atendimento_stream(self, usuario, relato, historico=""):
        inicio_atendimento = time.time()
        
        # Busca Sem√¢ntica no FAISS
        docs = self.vectorstore.similarity_search(relato, k=1)
        contexto = docs[0].page_content if docs else "Geral"
        sistema_detectado = docs[0].metadata["sistema"] if docs else "Geral"
        
        prompt_final = (
            f"Aja como suporte t√©cnico n√≠vel 2. Use o CONTEXTO: {contexto}\n"
            f"PERGUNTA: {relato}\n"
            f"INSTRU√á√ÉO: V√° DIRETO AOS PASSOS T√âCNICOS. "
            f"N√£o use sauda√ß√µes ou introdu√ß√µes. Use t√≥picos curtos. "
            f"Foque em: 1. Porta USB/LED, 2. SafeNet/ePass (instala√ß√£o), 3. Restart Smart Card (services.msc), 4. Limpeza de cache/Navegador."
        )
        
        full_response = ""
        
        try:
            print("üì° Solicitando resposta ao Google...")
            # Chamada direta via invoke (mais est√°vel para Python 3.9)
            resposta = self.llm.invoke(prompt_final)
            
            # Extra√ß√£o do texto
            full_response = getattr(resposta, 'content', str(resposta))
            full_response = full_response.replace("content=", "").strip("'\"")
            
            # Entrega a resposta para o app.py
            yield full_response

        except Exception as e:
            print(f"‚ùå Erro na IA: {str(e)}")
            yield f"\n‚ö†Ô∏è Ocorreu um erro na comunica√ß√£o. Por favor, tente novamente."
            full_response = ""

        # C√ÅLCULO DE TEMPO CORRIGIDO
        tempo_final_calculado = time.time() - inicio_atendimento
        print(f"üìä PERFORMANCE | Total: {tempo_final_calculado:.2f}s")
        
        # Grava√ß√£o no Banco de Dados (Firestore)
        if full_response:
            try:
                db.collection('atendimentos').add({
                    'usuario': usuario, 
                    'relato': relato, 
                    'sistema': sistema_detectado,
                    'tempo_processamento': tempo_final_calculado, # Vari√°vel agora definida corretamente
                    'data': firestore.SERVER_TIMESTAMP
                })
                print("‚úÖ Atendimento registrado no Firebase.")
            except Exception as e_db:
                print(f"‚ö†Ô∏è Erro ao gravar no Firebase (mas a resposta foi enviada): {e_db}")

# Inst√¢ncia global do motor
try:
    agente = MotorIA()
except Exception as e:
    print(f"Erro ao iniciar MotorIA: {e}")
    agente = None

def consultar_ia_stream(usuario, relato, historico=""):
    if agente:
        for resposta_parcial in agente.processar_atendimento_stream(usuario, relato, historico):
            if resposta_parcial:
                yield resposta_parcial
    else:
        yield "‚ùå Sistema de IA indispon√≠vel."